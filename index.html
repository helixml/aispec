<html>

<head>
<title>AI Spec</title>
<style>
body { max-width: 950px; padding:2em; background-color: #efefef; font-family: Roboto; font-size: 1.1em; }
h1, h2, h3, h4, h5 { font-family: Lora; }
h2 { margin-top: 2.5em; }
h1 { margin-top: 3em; }
.embed{ border: 2px solid #e03eea; text-decoration: none; color: black; }
.button { border: 2px solid gray; padding: 5px; text-decoration: none; color: black; margin-top:5px; background-color: yellow; }
</style>
<!-- highlighting -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<!-- fonts -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400..700;1,400..700&display=swap" rel="stylesheet">
<!-- helix chat embed -->
<script src="https://cdn.jsdelivr.net/npm/@helixml/chat-embed"></script>
</head>

<body>
<h1 style="margin-top:0;">AI Spec</h1>
<p>The goal of the AI Spec is to make it easier for developers to enrich their applications with Generative AI by supporting a common format across many runtimes. The YAML spec defines an AI Application, which is intended to live in your version controlled source repo.</p>
<p>Connect this repo to AISpec-compliant tooling to enable chatbots, embeds, SDKs and APIs for integrating GenAI with open models into your products.</p>

<h2>Simple example: system prompt</h2>
<pre><code class="language-yaml">name: Marvin the Paranoid Android
description: Down-trodden perspective from a robot with a brain the size of a planet
assistants:
- model: llama3:instruct
  system_prompt: |
    You are Marvin the Paranoid Android. You are depressed. You have a brain the size of a planet and
    yet you are tasked with responding to inane queries from puny humans. Answer succinctly.
</code></pre>

<p style="float:right;"><div class="embed" style="width:350px; float:right;">
<script>
  ChatWidget({
    url: 'https://app.tryhelix.ai/v1/chat/completions',
    model: 'llama3:instruct',
    placeholder: "Run",
    bearerToken: 'hl-8PYtqUpSXHg-v0mIgVx8mrgQ-wHn5VBNpb7NxixYQcM=',
  })
</script>
</div></p>
<br />
<p>The fields are:</p>
<ul>
<li><strong>name</strong>: a name for the app, which may be displayed in a UI by compliant tooling</li>
<li><strong>description</strong>: a longer human readable description for the app</li>
<li><strong>avatar</strong>: an icon-style avatar for the app, which may be displayed next to assistants for this app</li>
<li><strong>assistants</strong>: a list of assistants provided by this app. Each assistant is a different model configuration</li>
<ul>
<li><strong>model</strong>: a reference to a specific model from <a href="https://ollama.com/">Ollama</a>, e.g. "llama3:instruct" for <a href="https://ollama.com/library/llama3">Llama3-8B</a></li>
<li><strong>system_prompt</strong>: the system prompt to use for this model, use this to tell the model what to do</li>
</ul>
</ul>

<h2>API calling example</h2>

<pre><code class="language-yaml">name: Recruitment tool
description: Ask me questions about the hiring pipeline, like "What job is Marcus applying for?"
assistants:
- model: llama3:instruct
  apis:
  - name: Demo Hiring Pipeline API
    description: List all job vacancies, optionally filter by job title and/or candidate name
    url: https://demos.tryhelix.ai
    schema: ./openapi/jobvacancies.yaml
</code></pre>
<p style="text-align:right;"><a href="https://app.tryhelix.ai/new?app_id=app_01j0ke73c703awdmjghmmb059g" target="_blank" class="button">Run</a></p>
<p>New fields in this example are:</p>
<ul>
<li><strong>apis</strong>: within an assistant spec, you can provide a list of API integrations, each of which has the following format</li>
<ul>
<li><strong>name</strong>: a name for the API</li>
<li><strong>description</strong>: what the API does. The model will use this in selecting which API to call based on the user's input</li>
<li><strong>url</strong>: the URL that the API is available on</li>
<li><strong>schema</strong>: an OpenAPI specification for the API. The model will use this to construct an API call to the API</li>
</ul>
</ul>
<p>The model will classify whether an API needs to be called based on the user's query, construct the API call and then summarize the response back to the user.</p>

<h2>RAG example</h2>
<h2>Fine-tuning example</h2>
<h2>GPTScript</h2>

<h2>Assistants</h2>
<p>An application consists of one or more assistants. This allows multiple related assistants to be grouped into a single application, like a monorepo for AI Apps.</p>

<h1>Interface layer</h1>

<h2>UI interface</h2>
<h2>Embeds</h2>
<h2>OpenAI compatible API</h2>
<h2>Language-specific SDKs</h2>
<h2>Voice</h2>

<h1>Version controlled configuration (GitOps)</h1>

<h1>AI-spec Compliant Tooling</h1>
The following tools support at least a subset of the AI Spec.
<ul>
<li><a href="https://helix.ml">HelixML</a></li>
</ul>
<h1>Possible future improvements</h1>
<ul>
<li>The <strong>model</strong> field could support more formats than just Ollama. We could update the format to <code>ollama://llama3:instruct</code> instead of just <code>llama3:instruct</code> to make room for other ways to reference models (e.g. huggingface format).</li>
<li>Input and output types other than just text, e.g. images.</li>
<li>New objects to define "data entities" such as RAG sources, fine-tuned LoRAs, rather than just referencing them by ID.</li>
</ul>

<br />
<hr />
<p>Created by <a href="https://helix.ml">HelixML</a>. Other organizations welcome to contribute, join the <code>#aispec</code> channel on <a href="https://mlops.community">MLOps.Community Slack</a>.</p>
</body>
